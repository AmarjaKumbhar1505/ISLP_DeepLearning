{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pretrained CNN models**\n",
    "Pretrained CNN models are convolutional neural networks that have been trained on large datasets and can be fine-tuned for specific tasks. These models have already learned to recognize general features and patterns in images, making them a good starting point for many computer vision tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of Pretrained CNN Models**\n",
    "\n",
    "**Reduced Training Time:** Pretrained models can be fine-tuned much faster than training a model from scratch.\n",
    "\n",
    "**Improved Performance:** Pretrained models have already learned to recognize general features and patterns in images, which can improve performance on specific tasks.\n",
    "\n",
    "**Transfer Learning:**  Pretrained models can be used as a starting point for other tasks, allowing for transfer learning.\n",
    "Popular Pretrained CNN Models\n",
    "\n",
    "\n",
    "* **VGG16:** A 16-layer convolutional neural network trained on the ImageNet dataset.\n",
    "* **ResNet50:** A 50-layer convolutional neural network trained on the ImageNet dataset.\n",
    "* **InceptionV3:** A 48-layer convolutional neural network trained on the ImageNet dataset.\n",
    "* **DenseNet121:** A 121-layer convolutional neural network trained on the ImageNet dataset.\n",
    "* **MobileNetV2:** A lightweight convolutional neural network trained on the ImageNet dataset.\n",
    "\n",
    "**Applications of Pretrained CNN Models**\n",
    "\n",
    "* **Image Classification:** Pretrained models can be fine-tuned for image classification tasks.\n",
    "* **Object Detection:** Pretrained models can be used as a starting point for object detection tasks.\n",
    "* **Segmentation:** Pretrained models can be used for image segmentation tasks.\n",
    "* **Image Generation:** Pretrained models can be used for image generation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOADING LIBRARIES**\n",
    "\n",
    "We are loading the necessary libraries for data analysis, modeling, and visualization. These libraries will be used for data processing, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:01:44.312692Z",
     "iopub.status.busy": "2024-09-30T13:01:44.312174Z",
     "iopub.status.idle": "2024-09-30T13:01:58.575788Z",
     "shell.execute_reply": "2024-09-30T13:01:58.574094Z",
     "shell.execute_reply.started": "2024-09-30T13:01:44.312643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ISLP in /home/amarja/anaconda3/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.9 in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (1.11.4)\n",
      "Requirement already satisfied: pandas>=0.20 in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (2.1.4)\n",
      "Requirement already satisfied: lxml in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (4.9.3)\n",
      "Requirement already satisfied: scikit-learn>=1.2 in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (1.2.2)\n",
      "Requirement already satisfied: joblib in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (1.2.0)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (0.14.0)\n",
      "Requirement already satisfied: lifelines in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (0.29.0)\n",
      "Requirement already satisfied: pygam in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (0.9.1)\n",
      "Requirement already satisfied: torch in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (2.4.1)\n",
      "Requirement already satisfied: pytorch-lightning in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (2.4.0)\n",
      "Requirement already satisfied: torchmetrics in /home/amarja/anaconda3/lib/python3.11/site-packages (from ISLP) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/amarja/anaconda3/lib/python3.11/site-packages (from pandas>=0.20->ISLP) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from pandas>=0.20->ISLP) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from pandas>=0.20->ISLP) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.2->ISLP) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/amarja/anaconda3/lib/python3.11/site-packages (from statsmodels>=0.13->ISLP) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/amarja/anaconda3/lib/python3.11/site-packages (from statsmodels>=0.13->ISLP) (24.1)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from lifelines->ISLP) (3.8.0)\n",
      "Requirement already satisfied: autograd>=1.5 in /home/amarja/anaconda3/lib/python3.11/site-packages (from lifelines->ISLP) (1.7.0)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /home/amarja/anaconda3/lib/python3.11/site-packages (from lifelines->ISLP) (0.5.0)\n",
      "Requirement already satisfied: formulaic>=0.2.2 in /home/amarja/anaconda3/lib/python3.11/site-packages (from lifelines->ISLP) (1.0.2)\n",
      "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from pygam->ISLP) (4.5.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/amarja/anaconda3/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]>=2022.5.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (4.9.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (0.11.7)\n",
      "Requirement already satisfied: filelock in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (1.12)\n",
      "Requirement already satisfied: networkx in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from torch->ISLP) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/amarja/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->ISLP) (12.3.101)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.3.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.14.1)\n",
      "Requirement already satisfied: requests in /home/amarja/anaconda3/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.9.3)\n",
      "Requirement already satisfied: setuptools in /home/amarja/anaconda3/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning->ISLP) (68.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/amarja/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (3.0.9)\n",
      "Requirement already satisfied: six in /home/amarja/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.2->statsmodels>=0.13->ISLP) (1.16.0)\n",
      "Requirement already satisfied: python-utils>=3.8.1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP) (3.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from jinja2->torch->ISLP) (2.1.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath>=0.19 in /home/amarja/anaconda3/lib/python3.11/site-packages (from sympy->torch->ISLP) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/amarja/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/amarja/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/amarja/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/amarja/anaconda3/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/amarja/anaconda3/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/amarja/anaconda3/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/amarja/anaconda3/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ISLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:01:58.580035Z",
     "iopub.status.busy": "2024-09-30T13:01:58.579050Z",
     "iopub.status.idle": "2024-09-30T13:01:58.587370Z",
     "shell.execute_reply": "2024-09-30T13:01:58.586055Z",
     "shell.execute_reply.started": "2024-09-30T13:01:58.579983Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "from sklearn.linear_model import \\\n",
    "     (LinearRegression,\n",
    "      LogisticRegression,\n",
    "      Lasso)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from sklearn.model_selection import \\\n",
    "     (train_test_split,\n",
    "      GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch-Specific Imports\n",
    "There are a number of imports for `torch`. (These are not\n",
    "included with `ISLP`, so must be installed separately.)\n",
    "First we import the main library\n",
    "and essential tools used to specify sequentially-structured networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:01:58.589667Z",
     "iopub.status.busy": "2024-09-30T13:01:58.589161Z",
     "iopub.status.idle": "2024-09-30T13:01:58.602170Z",
     "shell.execute_reply": "2024-09-30T13:01:58.600984Z",
     "shell.execute_reply.started": "2024-09-30T13:01:58.589616Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several other helper packages for `torch`. For instance,\n",
    "the `torchmetrics` package has utilities to compute\n",
    "various metrics to evaluate performance when fitting\n",
    "a model. The `torchinfo` package provides a useful\n",
    "summary of the layers of a model. We use the `read_image()`\n",
    "function when loading test images in Section 10.9.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:01:58.604974Z",
     "iopub.status.busy": "2024-09-30T13:01:58.603497Z",
     "iopub.status.idle": "2024-09-30T13:01:58.614464Z",
     "shell.execute_reply": "2024-09-30T13:01:58.613180Z",
     "shell.execute_reply.started": "2024-09-30T13:01:58.604918Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchmetrics import (MeanAbsoluteError,\n",
    "                          R2Score)\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package `pytorch_lightning` is a somewhat higher-level\n",
    "interface to `torch` that simplifies the specification and\n",
    "fitting of\n",
    "models by reducing the amount of boilerplate code needed\n",
    "(compared to using `torch` alone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:01:58.618855Z",
     "iopub.status.busy": "2024-09-30T13:01:58.617899Z",
     "iopub.status.idle": "2024-09-30T13:01:58.627273Z",
     "shell.execute_reply": "2024-09-30T13:01:58.626216Z",
     "shell.execute_reply.started": "2024-09-30T13:01:58.618769Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reproduce results we use `seed_everything()`. We will also instruct `torch` to use deterministic algorithms\n",
    "where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:01:58.629437Z",
     "iopub.status.busy": "2024-09-30T13:01:58.628953Z",
     "iopub.status.idle": "2024-09-30T13:01:58.641429Z",
     "shell.execute_reply": "2024-09-30T13:01:58.640321Z",
     "shell.execute_reply.started": "2024-09-30T13:01:58.629382Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(0, workers=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use several datasets shipped with `torchvision` for our\n",
    "examples: a pretrained network for image classification,\n",
    "as well as some transforms used for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:01:58.643509Z",
     "iopub.status.busy": "2024-09-30T13:01:58.643057Z",
     "iopub.status.idle": "2024-09-30T13:01:59.015336Z",
     "shell.execute_reply": "2024-09-30T13:01:59.014249Z",
     "shell.execute_reply.started": "2024-09-30T13:01:58.643458Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.datasets import MNIST, CIFAR100\n",
    "from torchvision.models import (resnet50,\n",
    "                                ResNet50_Weights)\n",
    "from torchvision.transforms import (Resize,\n",
    "                                    Normalize,\n",
    "                                    CenterCrop,\n",
    "                                    ToTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided a few utilities in `ISLP` specifically for this lab.\n",
    "The `SimpleDataModule` and `SimpleModule` are simple\n",
    "versions of objects used in `pytorch_lightning`, the\n",
    "high-level module for fitting `torch` models. Although more advanced\n",
    "uses such as computing on graphical processing units (GPUs) and parallel data processing\n",
    "are possible in this module, we will not be focusing much on these\n",
    "in this lab. The `ErrorTracker` handles\n",
    "collections of targets and predictions over each mini-batch\n",
    "in the validation or test stage, allowing computation\n",
    "of the metric over the entire validation or test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:01:59.016990Z",
     "iopub.status.busy": "2024-09-30T13:01:59.016634Z",
     "iopub.status.idle": "2024-09-30T13:01:59.025084Z",
     "shell.execute_reply": "2024-09-30T13:01:59.023888Z",
     "shell.execute_reply.started": "2024-09-30T13:01:59.016953Z"
    }
   },
   "outputs": [],
   "source": [
    "from ISLP.torch import (SimpleDataModule,\n",
    "                        SimpleModule,\n",
    "                        ErrorTracker,\n",
    "                        rec_num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition we have included some helper\n",
    "functions to load the\n",
    "`IMDb` database, as well as a lookup that maps integers\n",
    "to particular keys in the database. We’ve included\n",
    "a slightly modified copy of the preprocessed\n",
    "`IMDb` data from `keras`, a separate package\n",
    "for fitting deep learning models. This saves us significant\n",
    "preprocessing and allows us to focus on specifying and fitting\n",
    "the models themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:01:59.026758Z",
     "iopub.status.busy": "2024-09-30T13:01:59.026381Z",
     "iopub.status.idle": "2024-09-30T13:01:59.340927Z",
     "shell.execute_reply": "2024-09-30T13:01:59.339699Z",
     "shell.execute_reply.started": "2024-09-30T13:01:59.026719Z"
    }
   },
   "outputs": [],
   "source": [
    "from ISLP.torch.imdb import (load_lookup,\n",
    "                             load_tensor,\n",
    "                             load_sparse,\n",
    "                             load_sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we introduce some utility imports  not directly related to\n",
    "`torch`.\n",
    "The `glob()` function from the `glob` module is used\n",
    "to find all files matching wildcard characters, which we will use\n",
    "in our example applying the `ResNet50` model\n",
    "to some of our own images.\n",
    "The `json` module will be used to load\n",
    "a JSON file for looking up classes to identify the labels of the\n",
    "pictures in the `ResNet50` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:01:59.342679Z",
     "iopub.status.busy": "2024-09-30T13:01:59.342317Z",
     "iopub.status.idle": "2024-09-30T13:01:59.348131Z",
     "shell.execute_reply": "2024-09-30T13:01:59.346882Z",
     "shell.execute_reply.started": "2024-09-30T13:01:59.342642Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yields approximately two- or three-fold  acceleration for each epoch.\n",
    "We have protected this code block using `try:` and `except:`\n",
    "clauses; if it works, we get the speedup, if it fails, nothing happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pretrained CNN Models\n",
    "We now show how to use a CNN pretrained on the  `imagenet` database to classify natural\n",
    "images, and demonstrate how we produced Figure 10.10.\n",
    "We copied six JPEG images from a digital photo album into the\n",
    "directory `book_images`. These images are available\n",
    "from the data section of  <www.statlearning.com>, the ISLP book website. Download `book_images.zip`; when\n",
    "clicked it creates the `book_images` directory. \n",
    "\n",
    "The pretrained network we use is called `resnet50`; specification details can be found on the web.\n",
    "We will read in the images, and\n",
    "convert them into the array format expected by the `torch`\n",
    "software to match the specifications in `resnet50`. \n",
    "The conversion involves a resize, a crop and then a predefined standardization for each of the three channels.\n",
    "We now read in the images and preprocess them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**\n",
    "\n",
    "**Resizing:** Resize images to 232x232 pixels with antialiasing.\n",
    "\n",
    "**Cropping:** Crop resized images to 224x224 pixels using center crop.\n",
    "\n",
    "**Normalization:** Normalize pixel values to have a mean of [0.485, 0.456, 0.406] and a standard deviation of [0.229, 0.224, 0.225].\n",
    "\n",
    "**Loading and Preprocessing:** Load images, apply resizing, cropping, and normalization, and stack them into a tensor.\n",
    "\n",
    "**Output:** A tensor of size (num_images, 3, 224, 224) containing the preprocessed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T13:05:47.976190Z",
     "iopub.status.busy": "2024-09-30T13:05:47.974871Z",
     "iopub.status.idle": "2024-09-30T13:05:48.030365Z",
     "shell.execute_reply": "2024-09-30T13:05:48.028395Z",
     "shell.execute_reply.started": "2024-09-30T13:05:47.976125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize = Resize((232,232), antialias=True)\n",
    "crop = CenterCrop(224)\n",
    "normalize = Normalize([0.485,0.456,0.406],\n",
    "                      [0.229,0.224,0.225])\n",
    "imgfiles = sorted([f for f in glob('book_images/*')])\n",
    "imgs = torch.stack([torch.div(crop(resize(read_image(f))), 255)\n",
    "                    for f in imgfiles])\n",
    "imgs = normalize(imgs)\n",
    "imgs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set up the trained network with the weights we read in code block~6. The model has 50 layers, with a fair bit of complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet-50 Architecture\n",
    "For this experiment, the ResNet-50 model was used, known for its deep structure and efficiency.\n",
    "ResNet-50 consists of 50 layers and is built using residual blocks with shortcut connections that allow gradients to flow more easily during backpropagation, solving the vanishing gradient problem commonly found in deep networks.\n",
    "\n",
    "### Key components:\n",
    "\n",
    "**Convolutional Layers:**  \n",
    "It begins with a 7x7 convolution followed by max-pooling to reduce input dimensions.\n",
    "\n",
    "**Residual Blocks:** The architecture includes 16 residual blocks, each with three convolutions (1x1, 3x3, and 1x1) that allow the model to learn deep features efficiently.\n",
    "\n",
    "**Bottleneck Layers:** 1x1 convolutions reduce computational complexity while maintaining depth.\n",
    "\n",
    "**Global Average Pooling:** Averages the features before a fully connected layer for classification.\n",
    "\n",
    "**Parameters:** The model has around 23 million parameters.\n",
    "\n",
    "ResNet-50 is well-suited for CIFAR-100 due to its ability to efficiently learn deep features without performance degradation, making it ideal for handling complex image classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-30T13:01:59.468583Z",
     "iopub.status.idle": "2024-09-30T13:01:59.469076Z",
     "shell.execute_reply": "2024-09-30T13:01:59.468863Z",
     "shell.execute_reply.started": "2024-09-30T13:01:59.468829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "ResNet                                   [6, 3, 224, 224]          [6, 1000]                 --\n",
       "├─Conv2d: 1-1                            [6, 3, 224, 224]          [6, 64, 112, 112]         9,408\n",
       "├─BatchNorm2d: 1-2                       [6, 64, 112, 112]         [6, 64, 112, 112]         128\n",
       "├─ReLU: 1-3                              [6, 64, 112, 112]         [6, 64, 112, 112]         --\n",
       "├─MaxPool2d: 1-4                         [6, 64, 112, 112]         [6, 64, 56, 56]           --\n",
       "├─Sequential: 1-5                        [6, 64, 56, 56]           [6, 256, 56, 56]          --\n",
       "│    └─Bottleneck: 2-1                   [6, 64, 56, 56]           [6, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-1                  [6, 64, 56, 56]           [6, 64, 56, 56]           4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [6, 64, 56, 56]           [6, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-3                    [6, 64, 56, 56]           [6, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-4                  [6, 64, 56, 56]           [6, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [6, 64, 56, 56]           [6, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-6                    [6, 64, 56, 56]           [6, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-7                  [6, 64, 56, 56]           [6, 256, 56, 56]          16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [6, 256, 56, 56]          [6, 256, 56, 56]          512\n",
       "│    │    └─Sequential: 3-9              [6, 64, 56, 56]           [6, 256, 56, 56]          16,896\n",
       "│    │    └─ReLU: 3-10                   [6, 256, 56, 56]          [6, 256, 56, 56]          --\n",
       "│    └─Bottleneck: 2-2                   [6, 256, 56, 56]          [6, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-11                 [6, 256, 56, 56]          [6, 64, 56, 56]           16,384\n",
       "│    │    └─BatchNorm2d: 3-12            [6, 64, 56, 56]           [6, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-13                   [6, 64, 56, 56]           [6, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-14                 [6, 64, 56, 56]           [6, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-15            [6, 64, 56, 56]           [6, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-16                   [6, 64, 56, 56]           [6, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-17                 [6, 64, 56, 56]           [6, 256, 56, 56]          16,384\n",
       "│    │    └─BatchNorm2d: 3-18            [6, 256, 56, 56]          [6, 256, 56, 56]          512\n",
       "│    │    └─ReLU: 3-19                   [6, 256, 56, 56]          [6, 256, 56, 56]          --\n",
       "│    └─Bottleneck: 2-3                   [6, 256, 56, 56]          [6, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-20                 [6, 256, 56, 56]          [6, 64, 56, 56]           16,384\n",
       "│    │    └─BatchNorm2d: 3-21            [6, 64, 56, 56]           [6, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-22                   [6, 64, 56, 56]           [6, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-23                 [6, 64, 56, 56]           [6, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-24            [6, 64, 56, 56]           [6, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-25                   [6, 64, 56, 56]           [6, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-26                 [6, 64, 56, 56]           [6, 256, 56, 56]          16,384\n",
       "│    │    └─BatchNorm2d: 3-27            [6, 256, 56, 56]          [6, 256, 56, 56]          512\n",
       "│    │    └─ReLU: 3-28                   [6, 256, 56, 56]          [6, 256, 56, 56]          --\n",
       "├─Sequential: 1-6                        [6, 256, 56, 56]          [6, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-4                   [6, 256, 56, 56]          [6, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-29                 [6, 256, 56, 56]          [6, 128, 56, 56]          32,768\n",
       "│    │    └─BatchNorm2d: 3-30            [6, 128, 56, 56]          [6, 128, 56, 56]          256\n",
       "│    │    └─ReLU: 3-31                   [6, 128, 56, 56]          [6, 128, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-32                 [6, 128, 56, 56]          [6, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [6, 128, 28, 28]          [6, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-34                   [6, 128, 28, 28]          [6, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-35                 [6, 128, 28, 28]          [6, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-36            [6, 512, 28, 28]          [6, 512, 28, 28]          1,024\n",
       "│    │    └─Sequential: 3-37             [6, 256, 56, 56]          [6, 512, 28, 28]          132,096\n",
       "│    │    └─ReLU: 3-38                   [6, 512, 28, 28]          [6, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-5                   [6, 512, 28, 28]          [6, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-39                 [6, 512, 28, 28]          [6, 128, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-40            [6, 128, 28, 28]          [6, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-41                   [6, 128, 28, 28]          [6, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-42                 [6, 128, 28, 28]          [6, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-43            [6, 128, 28, 28]          [6, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-44                   [6, 128, 28, 28]          [6, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-45                 [6, 128, 28, 28]          [6, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-46            [6, 512, 28, 28]          [6, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-47                   [6, 512, 28, 28]          [6, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-6                   [6, 512, 28, 28]          [6, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-48                 [6, 512, 28, 28]          [6, 128, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-49            [6, 128, 28, 28]          [6, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-50                   [6, 128, 28, 28]          [6, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-51                 [6, 128, 28, 28]          [6, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-52            [6, 128, 28, 28]          [6, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-53                   [6, 128, 28, 28]          [6, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-54                 [6, 128, 28, 28]          [6, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-55            [6, 512, 28, 28]          [6, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-56                   [6, 512, 28, 28]          [6, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-7                   [6, 512, 28, 28]          [6, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-57                 [6, 512, 28, 28]          [6, 128, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-58            [6, 128, 28, 28]          [6, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-59                   [6, 128, 28, 28]          [6, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-60                 [6, 128, 28, 28]          [6, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-61            [6, 128, 28, 28]          [6, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-62                   [6, 128, 28, 28]          [6, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-63                 [6, 128, 28, 28]          [6, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [6, 512, 28, 28]          [6, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-65                   [6, 512, 28, 28]          [6, 512, 28, 28]          --\n",
       "├─Sequential: 1-7                        [6, 512, 28, 28]          [6, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-8                   [6, 512, 28, 28]          [6, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-66                 [6, 512, 28, 28]          [6, 256, 28, 28]          131,072\n",
       "│    │    └─BatchNorm2d: 3-67            [6, 256, 28, 28]          [6, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-68                   [6, 256, 28, 28]          [6, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-69                 [6, 256, 28, 28]          [6, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-71                   [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-72                 [6, 256, 14, 14]          [6, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-73            [6, 1024, 14, 14]         [6, 1024, 14, 14]         2,048\n",
       "│    │    └─Sequential: 3-74             [6, 512, 28, 28]          [6, 1024, 14, 14]         526,336\n",
       "│    │    └─ReLU: 3-75                   [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-9                   [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-76                 [6, 1024, 14, 14]         [6, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-77            [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-78                   [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-79                 [6, 256, 14, 14]          [6, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-80            [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-81                   [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-82                 [6, 256, 14, 14]          [6, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-83            [6, 1024, 14, 14]         [6, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-84                   [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-10                  [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-85                 [6, 1024, 14, 14]         [6, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-86            [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-87                   [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-88                 [6, 256, 14, 14]          [6, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-89            [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-90                   [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-91                 [6, 256, 14, 14]          [6, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-92            [6, 1024, 14, 14]         [6, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-93                   [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-11                  [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-94                 [6, 1024, 14, 14]         [6, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-96                   [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-97                 [6, 256, 14, 14]          [6, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-99                   [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-100                [6, 256, 14, 14]          [6, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [6, 1024, 14, 14]         [6, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-102                  [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-12                  [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-103                [6, 1024, 14, 14]         [6, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-104           [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-105                  [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-106                [6, 256, 14, 14]          [6, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-107           [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-108                  [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-109                [6, 256, 14, 14]          [6, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-110           [6, 1024, 14, 14]         [6, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-111                  [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-13                  [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-112                [6, 1024, 14, 14]         [6, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-113           [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-114                  [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-115                [6, 256, 14, 14]          [6, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-116           [6, 256, 14, 14]          [6, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-117                  [6, 256, 14, 14]          [6, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-118                [6, 256, 14, 14]          [6, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-119           [6, 1024, 14, 14]         [6, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-120                  [6, 1024, 14, 14]         [6, 1024, 14, 14]         --\n",
       "├─Sequential: 1-8                        [6, 1024, 14, 14]         [6, 2048, 7, 7]           --\n",
       "│    └─Bottleneck: 2-14                  [6, 1024, 14, 14]         [6, 2048, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-121                [6, 1024, 14, 14]         [6, 512, 14, 14]          524,288\n",
       "│    │    └─BatchNorm2d: 3-122           [6, 512, 14, 14]          [6, 512, 14, 14]          1,024\n",
       "│    │    └─ReLU: 3-123                  [6, 512, 14, 14]          [6, 512, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-124                [6, 512, 14, 14]          [6, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-125           [6, 512, 7, 7]            [6, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-126                  [6, 512, 7, 7]            [6, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-127                [6, 512, 7, 7]            [6, 2048, 7, 7]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-128           [6, 2048, 7, 7]           [6, 2048, 7, 7]           4,096\n",
       "│    │    └─Sequential: 3-129            [6, 1024, 14, 14]         [6, 2048, 7, 7]           2,101,248\n",
       "│    │    └─ReLU: 3-130                  [6, 2048, 7, 7]           [6, 2048, 7, 7]           --\n",
       "│    └─Bottleneck: 2-15                  [6, 2048, 7, 7]           [6, 2048, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-131                [6, 2048, 7, 7]           [6, 512, 7, 7]            1,048,576\n",
       "│    │    └─BatchNorm2d: 3-132           [6, 512, 7, 7]            [6, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-133                  [6, 512, 7, 7]            [6, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-134                [6, 512, 7, 7]            [6, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-135           [6, 512, 7, 7]            [6, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-136                  [6, 512, 7, 7]            [6, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-137                [6, 512, 7, 7]            [6, 2048, 7, 7]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-138           [6, 2048, 7, 7]           [6, 2048, 7, 7]           4,096\n",
       "│    │    └─ReLU: 3-139                  [6, 2048, 7, 7]           [6, 2048, 7, 7]           --\n",
       "│    └─Bottleneck: 2-16                  [6, 2048, 7, 7]           [6, 2048, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-140                [6, 2048, 7, 7]           [6, 512, 7, 7]            1,048,576\n",
       "│    │    └─BatchNorm2d: 3-141           [6, 512, 7, 7]            [6, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-142                  [6, 512, 7, 7]            [6, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-143                [6, 512, 7, 7]            [6, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-144           [6, 512, 7, 7]            [6, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-145                  [6, 512, 7, 7]            [6, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-146                [6, 512, 7, 7]            [6, 2048, 7, 7]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-147           [6, 2048, 7, 7]           [6, 2048, 7, 7]           4,096\n",
       "│    │    └─ReLU: 3-148                  [6, 2048, 7, 7]           [6, 2048, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [6, 2048, 7, 7]           [6, 2048, 1, 1]           --\n",
       "├─Linear: 1-10                           [6, 2048]                 [6, 1000]                 2,049,000\n",
       "===================================================================================================================\n",
       "Total params: 25,557,032\n",
       "Trainable params: 25,557,032\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 24.54\n",
       "===================================================================================================================\n",
       "Input size (MB): 3.61\n",
       "Forward/backward pass size (MB): 1066.99\n",
       "Params size (MB): 102.23\n",
       "Estimated Total Size (MB): 1172.83\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "summary(resnet_model,\n",
    "        input_data=imgs,\n",
    "        col_names=['input_size',\n",
    "                   'output_size',\n",
    "                   'num_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the mode to `eval()` to ensure that the model is ready to predict on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-30T13:01:59.471307Z",
     "iopub.status.idle": "2024-09-30T13:01:59.471732Z",
     "shell.execute_reply": "2024-09-30T13:01:59.471546Z",
     "shell.execute_reply.started": "2024-09-30T13:01:59.471525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the output above, we see that when setting up the\n",
    "`resnet_model`, the authors defined a `Bottleneck`, much like our\n",
    "`BuildingBlock` module.\n",
    "\n",
    "We now feed our six images through the fitted network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions (img_preds) by applying the trained ResNet-50 model to the input images. The model outputs a set of probabilities for each class (in the case of CIFAR-100, 100 possible classes). These predictions are then used to evaluate the performance of the model by comparing them to the ground truth labels, allowing for the calculation of metrics such as accuracy and loss.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-30T13:01:59.473414Z",
     "iopub.status.idle": "2024-09-30T13:01:59.473858Z",
     "shell.execute_reply": "2024-09-30T13:01:59.473642Z",
     "shell.execute_reply.started": "2024-09-30T13:01:59.473621Z"
    }
   },
   "outputs": [],
   "source": [
    "img_preds = resnet_model(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at the predicted probabilities for each of the top 3 choices. First we compute\n",
    "the probabilities by applying the softmax to the logits in `img_preds`. Note that\n",
    "we have had to call the `detach()` method on the tensor `img_preds` in order to convert\n",
    "it to our a more familiar `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-30T13:01:59.475232Z",
     "iopub.status.idle": "2024-09-30T13:01:59.475664Z",
     "shell.execute_reply": "2024-09-30T13:01:59.475472Z",
     "shell.execute_reply.started": "2024-09-30T13:01:59.475450Z"
    }
   },
   "outputs": [],
   "source": [
    "img_probs = np.exp(np.asarray(img_preds.detach()))\n",
    "img_probs /= img_probs.sum(1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the class labels, we must download the index file associated with `imagenet`. {This is avalable from the book website and  [s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json](https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json).}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-30T13:01:59.477016Z",
     "iopub.status.idle": "2024-09-30T13:01:59.477432Z",
     "shell.execute_reply": "2024-09-30T13:01:59.477246Z",
     "shell.execute_reply.started": "2024-09-30T13:01:59.477225Z"
    }
   },
   "outputs": [],
   "source": [
    "labs = json.load(open('imagenet_class_index.json'))\n",
    "class_labels = pd.DataFrame([(int(k), v[1]) for k, v in \n",
    "                           labs.items()],\n",
    "                           columns=['idx', 'label'])\n",
    "class_labels = class_labels.set_index('idx')\n",
    "class_labels = class_labels.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll now construct a data frame for each image file\n",
    "with the labels with the three highest probabilities as\n",
    "estimated by the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-30T13:01:59.478960Z",
     "iopub.status.idle": "2024-09-30T13:01:59.479385Z",
     "shell.execute_reply": "2024-09-30T13:01:59.479195Z",
     "shell.execute_reply.started": "2024-09-30T13:01:59.479173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: book_images/Cape_Weaver.jpg\n",
      "      label      prob\n",
      "0   jacamar  0.297499\n",
      "1     macaw  0.068107\n",
      "2  lorikeet  0.051104\n",
      "Image: book_images/Flamingo.jpg\n",
      "            label      prob\n",
      "0        flamingo  0.609515\n",
      "1       spoonbill  0.013586\n",
      "2  American_egret  0.002132\n",
      "Image: book_images/Hawk_Fountain.jpg\n",
      "            label      prob\n",
      "0            kite  0.184681\n",
      "1           robin  0.084022\n",
      "2  great_grey_owl  0.061274\n",
      "Image: book_images/Hawk_cropped.jpg\n",
      "            label      prob\n",
      "0            kite  0.453834\n",
      "1  great_grey_owl  0.015914\n",
      "2             jay  0.012210\n",
      "Image: book_images/Lhasa_Apso.jpg\n",
      "             label      prob\n",
      "0            Lhasa  0.260316\n",
      "1         Shih-Tzu  0.097196\n",
      "2  Tibetan_terrier  0.032820\n",
      "Image: book_images/Sleeping_Cat.jpg\n",
      "         label      prob\n",
      "0  Persian_cat  0.163069\n",
      "1        tabby  0.074143\n",
      "2    tiger_cat  0.042578\n"
     ]
    }
   ],
   "source": [
    "for i, imgfile in enumerate(imgfiles):\n",
    "    img_df = class_labels.copy()\n",
    "    img_df['prob'] = img_probs[i]\n",
    "    img_df = img_df.sort_values(by='prob', ascending=False)[:3]\n",
    "    print(f'Image: {imgfile}')\n",
    "    print(img_df.reset_index().drop(columns=['idx']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model\n",
    "is quite confident about `Flamingo.jpg`, but a little less so for the\n",
    "other images.\n",
    "\n",
    "We end this section with our usual cleanup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the provided predictions and probabilities for each image, here are the observations:\n",
    "\n",
    "**Image: Cape Weaver**\n",
    "\n",
    "- The model's top prediction is jacamar with a probability of 29.75%, followed by macaw and lorikeet with much lower probabilities.\n",
    "\n",
    "- The model shows some confusion, likely because the Cape Weaver bird is not in the top predictions, suggesting that it struggles with this image.\n",
    "\n",
    "**Image: Flamingo**\n",
    "\n",
    "- The model confidently predicts flamingo with a probability of 60.95%, which is a correct classification.\n",
    "Other less likely predictions include spoonbill and American egret, with minimal probabilities.\n",
    "Image: Hawk Fountain\n",
    "\n",
    "- The model predicts kite as the top class with a probability of 18.47%, though with relatively low confidence.\n",
    "Other predictions, such as robin and great grey owl, indicate uncertainty in classifying this image.\n",
    "\n",
    "**Image: Hawk Cropped**\n",
    "\n",
    "- The model once again predicts kite with higher confidence (45.38%).\n",
    "- Lower-ranked predictions include great grey owl and jay, suggesting the cropped image gave clearer visual cues for the correct class.\n",
    "\n",
    "**Image: Lhasa Apso**\n",
    "\n",
    "- The model's top prediction is Lhasa with 26.03% probability, followed by Shih-Tzu and Tibetan terrier.\n",
    "- These predictions are reasonable as the Lhasa Apso dog breed shares visual similarities with these other breeds, although the confidence is not very high.\n",
    "\n",
    "**Image: Sleeping Cat**\n",
    "\n",
    "- The model predicts Persian cat as the most likely class with 16.31% confidence, followed by tabby and tiger cat.\n",
    "- The relatively low probabilities suggest the model is uncertain, which could be due to similarities between various types of cats in the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Observations:\n",
    "\n",
    "**The model performs well on some images, such as the flamingo, but struggles with others, especially when visual similarity across classes (e.g., different types of birds or dogs) is high.**\n",
    "\n",
    "**In cases like the Cape Weaver and Hawk Fountain, the model is uncertain or incorrect, highlighting potential areas where fine-tuning or more data might help improve accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md:myst",
   "main_language": "python"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 198900895,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152e0400",
   "metadata": {},
   "source": [
    "# 10.9.1Single Layer Network on Hitters Data\n",
    "\n",
    "The primary goal of this project is to develop a robust machine learning model that can accurately predict the salaries of baseball players based on their performance statistics and their overall career data.By analyzing various factors that contribute to a player's salary,the model will provide valuable insights into the dynamics of player valuation within professional baseball.The project seeks to address the challange of predicting salaries in a field where numerous performance metrics and historical data influence player earnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67a687",
   "metadata": {},
   "source": [
    "## LOADING LIBRARIES\n",
    "We are loading the necessary libraries for data analysis, modeling, and visualization. These libraries will be used for data processing, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf886666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:15.897816Z",
     "iopub.status.busy": "2024-09-29T20:05:15.897192Z",
     "iopub.status.idle": "2024-09-29T20:05:28.046978Z",
     "shell.execute_reply": "2024-09-29T20:05:28.045405Z",
     "shell.execute_reply.started": "2024-09-29T20:05:15.897767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ISLP in /opt/conda/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from ISLP) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.9 in /opt/conda/lib/python3.10/site-packages (from ISLP) (1.11.4)\n",
      "Requirement already satisfied: pandas>=0.20 in /opt/conda/lib/python3.10/site-packages (from ISLP) (2.2.2)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from ISLP) (5.3.0)\n",
      "Requirement already satisfied: scikit-learn>=1.2 in /opt/conda/lib/python3.10/site-packages (from ISLP) (1.2.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from ISLP) (1.4.2)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /opt/conda/lib/python3.10/site-packages (from ISLP) (0.14.2)\n",
      "Requirement already satisfied: lifelines in /opt/conda/lib/python3.10/site-packages (from ISLP) (0.29.0)\n",
      "Requirement already satisfied: pygam in /opt/conda/lib/python3.10/site-packages (from ISLP) (0.9.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from ISLP) (2.4.0+cpu)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from ISLP) (2.4.0)\n",
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (from ISLP) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.20->ISLP) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.20->ISLP) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.20->ISLP) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2->ISLP) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13->ISLP) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13->ISLP) (21.3)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /opt/conda/lib/python3.10/site-packages (from lifelines->ISLP) (3.7.5)\n",
      "Requirement already satisfied: autograd>=1.5 in /opt/conda/lib/python3.10/site-packages (from lifelines->ISLP) (1.7.0)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /opt/conda/lib/python3.10/site-packages (from lifelines->ISLP) (0.5.0)\n",
      "Requirement already satisfied: formulaic>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from lifelines->ISLP) (1.0.2)\n",
      "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pygam->ISLP) (4.5.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning->ISLP) (4.66.4)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning->ISLP) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning->ISLP) (4.12.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning->ISLP) (0.11.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->ISLP) (3.15.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->ISLP) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->ISLP) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->ISLP) (3.1.4)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.3.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in /opt/conda/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.16.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.9.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning->ISLP) (70.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines->ISLP) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines->ISLP) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines->ISLP) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines->ISLP) (3.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.6->statsmodels>=0.13->ISLP) (1.16.0)\n",
      "Requirement already satisfied: python-utils>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP) (3.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->ISLP) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->ISLP) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ISLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac5dfa57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:28.050015Z",
     "iopub.status.busy": "2024-09-29T20:05:28.049617Z",
     "iopub.status.idle": "2024-09-29T20:05:28.058830Z",
     "shell.execute_reply": "2024-09-29T20:05:28.057494Z",
     "shell.execute_reply.started": "2024-09-29T20:05:28.049973Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ISLP import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras \n",
    "from keras import Sequential \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import \\\n",
    "     (LinearRegression,\n",
    "      LogisticRegression,\n",
    "      Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a1193",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7347cb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:28.061245Z",
     "iopub.status.busy": "2024-09-29T20:05:28.060729Z",
     "iopub.status.idle": "2024-09-29T20:05:28.081959Z",
     "shell.execute_reply": "2024-09-29T20:05:28.080780Z",
     "shell.execute_reply.started": "2024-09-29T20:05:28.061162Z"
    }
   },
   "outputs": [],
   "source": [
    "df = load_data('Hitters').dropna()\n",
    "n = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c344c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:28.084149Z",
     "iopub.status.busy": "2024-09-29T20:05:28.083736Z",
     "iopub.status.idle": "2024-09-29T20:05:28.107783Z",
     "shell.execute_reply": "2024-09-29T20:05:28.106632Z",
     "shell.execute_reply.started": "2024-09-29T20:05:28.084109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  CRuns  \\\n",
       "1    315    81      7    24   38     39     14    3449    835      69    321   \n",
       "2    479   130     18    66   72     76      3    1624    457      63    224   \n",
       "3    496   141     20    65   78     37     11    5628   1575     225    828   \n",
       "4    321    87     10    39   42     30      2     396    101      12     48   \n",
       "5    594   169      4    74   51     35     11    4408   1133      19    501   \n",
       "\n",
       "   CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary NewLeague  \n",
       "1   414     375      N        W      632       43      10   475.0         N  \n",
       "2   266     263      A        W      880       82      14   480.0         A  \n",
       "3   838     354      N        E      200       11       3   500.0         N  \n",
       "4    46      33      N        E      805       40       4    91.5         N  \n",
       "5   336     194      A        W      282      421      25   750.0         A  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d3823",
   "metadata": {},
   "source": [
    "In this dataset, several variables such as League, Division, and NewLeague are categorical. These variables play a significant role in the analysis; however, regression models require numerical input to operate correctly. Using categorical variables in their original form could lead to errors or misinterpretations, as regression models cannot process non-numerical data effectively.\n",
    "\n",
    "To address this issue, I am transforming the categorical variables into a binary format using One-Hot Encoding. This technique converts each category into a unique numerical representation (0 or 1), which allows the regression model to interpret these variables properly. By doing so, I ensure that the model can utilize all the variables appropriately during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c386a442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:28.112242Z",
     "iopub.status.busy": "2024-09-29T20:05:28.110958Z",
     "iopub.status.idle": "2024-09-29T20:05:28.143523Z",
     "shell.execute_reply": "2024-09-29T20:05:28.142393Z",
     "shell.execute_reply.started": "2024-09-29T20:05:28.112193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>...</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>League_A</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_E</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_A</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  ...  \\\n",
       "1    315    81      7    24   38     39     14    3449    835      69  ...   \n",
       "2    479   130     18    66   72     76      3    1624    457      63  ...   \n",
       "3    496   141     20    65   78     37     11    5628   1575     225  ...   \n",
       "4    321    87     10    39   42     30      2     396    101      12  ...   \n",
       "5    594   169      4    74   51     35     11    4408   1133      19  ...   \n",
       "\n",
       "   PutOuts  Assists  Errors  Salary  League_A  League_N  Division_E  \\\n",
       "1      632       43      10   475.0     False      True       False   \n",
       "2      880       82      14   480.0      True     False       False   \n",
       "3      200       11       3   500.0     False      True        True   \n",
       "4      805       40       4    91.5     False      True        True   \n",
       "5      282      421      25   750.0      True     False       False   \n",
       "\n",
       "   Division_W  NewLeague_A  NewLeague_N  \n",
       "1        True        False         True  \n",
       "2        True         True        False  \n",
       "3       False        False         True  \n",
       "4       False        False         True  \n",
       "5        True         True        False  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.get_dummies(df,columns=[\"League\",\"Division\",'NewLeague'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e1939",
   "metadata": {},
   "source": [
    "### Split the selected independent feature and target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9df8681e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:28.145408Z",
     "iopub.status.busy": "2024-09-29T20:05:28.144918Z",
     "iopub.status.idle": "2024-09-29T20:05:28.151763Z",
     "shell.execute_reply": "2024-09-29T20:05:28.150399Z",
     "shell.execute_reply.started": "2024-09-29T20:05:28.145348Z"
    }
   },
   "outputs": [],
   "source": [
    "X=df.drop(columns=['Salary'])\n",
    "y=df['Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd0fcdb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:28.153672Z",
     "iopub.status.busy": "2024-09-29T20:05:28.153264Z",
     "iopub.status.idle": "2024-09-29T20:05:28.185575Z",
     "shell.execute_reply": "2024-09-29T20:05:28.184362Z",
     "shell.execute_reply.started": "2024-09-29T20:05:28.153622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>...</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_A</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_E</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_A</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>375</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>263</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>354</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>138</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>875</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>332</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>249</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  ...  \\\n",
       "1      315    81      7    24   38     39     14    3449    835      69  ...   \n",
       "2      479   130     18    66   72     76      3    1624    457      63  ...   \n",
       "3      496   141     20    65   78     37     11    5628   1575     225  ...   \n",
       "4      321    87     10    39   42     30      2     396    101      12  ...   \n",
       "5      594   169      4    74   51     35     11    4408   1133      19  ...   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...  ...   \n",
       "317    497   127      7    65   48     37      5    2703    806      32  ...   \n",
       "318    492   136      5    76   50     94     12    5511   1511      39  ...   \n",
       "319    475   126      3    61   43     52      6    1700    433       7  ...   \n",
       "320    573   144      9    85   60     78      8    3198    857      97  ...   \n",
       "321    631   170      9    77   44     31     11    4908   1457      30  ...   \n",
       "\n",
       "     CWalks  PutOuts  Assists  Errors  League_A  League_N  Division_E  \\\n",
       "1       375      632       43      10     False      True       False   \n",
       "2       263      880       82      14      True     False       False   \n",
       "3       354      200       11       3     False      True        True   \n",
       "4        33      805       40       4     False      True        True   \n",
       "5       194      282      421      25      True     False       False   \n",
       "..      ...      ...      ...     ...       ...       ...         ...   \n",
       "317     138      325        9       3     False      True        True   \n",
       "318     875      313      381      20      True     False        True   \n",
       "319     146       37      113       7      True     False       False   \n",
       "320     332     1314      131      12      True     False        True   \n",
       "321     249      408        4       3      True     False       False   \n",
       "\n",
       "     Division_W  NewLeague_A  NewLeague_N  \n",
       "1          True        False         True  \n",
       "2          True         True        False  \n",
       "3         False        False         True  \n",
       "4         False        False         True  \n",
       "5          True         True        False  \n",
       "..          ...          ...          ...  \n",
       "317       False        False         True  \n",
       "318       False         True        False  \n",
       "319        True         True        False  \n",
       "320       False         True        False  \n",
       "321        True         True        False  \n",
       "\n",
       "[263 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dbdf82b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:28.187783Z",
     "iopub.status.busy": "2024-09-29T20:05:28.187263Z",
     "iopub.status.idle": "2024-09-29T20:05:28.205125Z",
     "shell.execute_reply": "2024-09-29T20:05:28.203655Z",
     "shell.execute_reply.started": "2024-09-29T20:05:28.187728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       475.0\n",
       "2       480.0\n",
       "3       500.0\n",
       "4        91.5\n",
       "5       750.0\n",
       "        ...  \n",
       "317     700.0\n",
       "318     875.0\n",
       "319     385.0\n",
       "320     960.0\n",
       "321    1000.0\n",
       "Name: Salary, Length: 263, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a194de",
   "metadata": {},
   "source": [
    "### Train test split:\n",
    "splits your dataset into two parts: training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "497587ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:28.207999Z",
     "iopub.status.busy": "2024-09-29T20:05:28.207630Z",
     "iopub.status.idle": "2024-09-29T20:05:28.225800Z",
     "shell.execute_reply": "2024-09-29T20:05:28.224228Z",
     "shell.execute_reply.started": "2024-09-29T20:05:28.207963Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78e55ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:28.229032Z",
     "iopub.status.busy": "2024-09-29T20:05:28.228015Z",
     "iopub.status.idle": "2024-09-29T20:05:28.243626Z",
     "shell.execute_reply": "2024-09-29T20:05:28.242206Z",
     "shell.execute_reply.started": "2024-09-29T20:05:28.228966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 22)\n",
      "(210, 22)\n",
      "(53,)\n",
      "(210,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cb41e7",
   "metadata": {},
   "source": [
    "### Normalize the Data\n",
    "\n",
    "In dataset, the variables I’m analyzing have different ranges. For example, the number of times at bat (AtBat) or the number of hits (Hits) can be in the hundreds, while the number of errors (Errors) might be much smaller. If I don’t normalize the data, the regression model could give more weight to variables with larger ranges, simply because their values are higher. This could lead to biased results and reduce the accuracy of my predictions.\n",
    "\n",
    "By normalizing the data, I bring all the variables onto a similar scale, typically between 0 and 1. This process ensures that each variable contributes equally to the model, regardless of its original range. As a result, the model can more accurately identify the relationships between the variables and the target variable, which in my case is the player’s salary during the 1986-1987 season.\n",
    "\n",
    "Normalization is a key step to prevent any one feature from disproportionately influencing the model, and it ultimately leads to more reliable and interpretable results in my analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fcb6c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:05:28.245563Z",
     "iopub.status.busy": "2024-09-29T20:05:28.245129Z",
     "iopub.status.idle": "2024-09-29T20:05:28.264894Z",
     "shell.execute_reply": "2024-09-29T20:05:28.263230Z",
     "shell.execute_reply.started": "2024-09-29T20:05:28.245516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the StandardScaler class from the sklearn.preprocessing module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an instance of the StandardScaler class\n",
    "Scaler = StandardScaler()\n",
    "\n",
    "# Scale the training data using the fit_transform method\n",
    "# This method scales the data to have a mean of 0 and a standard deviation of 1\n",
    "X_train_scaled = Scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the test data using the transform method\n",
    "# This method scales the data using the same scaling factors as the training data\n",
    "X_test_scaled = Scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc03279",
   "metadata": {},
   "source": [
    "## Linear Models\n",
    "We fit the linear model and evaluate the test error directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36c1a985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:06:25.065458Z",
     "iopub.status.busy": "2024-09-29T20:06:25.064976Z",
     "iopub.status.idle": "2024-09-29T20:06:25.078684Z",
     "shell.execute_reply": "2024-09-29T20:06:25.077466Z",
     "shell.execute_reply.started": "2024-09-29T20:06:25.065415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 268.32\n",
      "R2 Score:  0.4166986480172825\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the LinearRegression class\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the linear regression model on the training data\n",
    "# X_train is the feature matrix and y_train is the target vector\n",
    "lin_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "# X_test is the feature matrix for the test data\n",
    "Yhat_test = lin_reg.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the mean absolute error (MAE) of the predictions\n",
    "# np.abs calculates the absolute difference between the predicted and actual values\n",
    "# .mean calculates the mean of the absolute differences\n",
    "mae_linear = np.abs(Yhat_test - y_test).mean()\n",
    "\n",
    "# Print the mean absolute error\n",
    "print(f'Mean Absolute Error: {mae_linear:.2f}')\n",
    "R2Score_linear=r2_score(y_test,Yhat_test)\n",
    "print(\"R2 Score: \",R2Score_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb69675d",
   "metadata": {},
   "source": [
    "# Lasso Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5e1eba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:06:44.397612Z",
     "iopub.status.busy": "2024-09-29T20:06:44.396976Z",
     "iopub.status.idle": "2024-09-29T20:06:44.421114Z",
     "shell.execute_reply": "2024-09-29T20:06:44.417044Z",
     "shell.execute_reply.started": "2024-09-29T20:06:44.397554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 263.72\n",
      "MSLE Score: 0.66\n",
      "R2 Score:  0.4388682580161326\n"
     ]
    }
   ],
   "source": [
    "# Define a custom scoring function to evaluate the model's performance\n",
    "# This function calculates the mean squared logarithmic error (MSLE) between the predicted and actual values\n",
    "def score(y_pred, y_true):\n",
    "    # Calculate the MSLE\n",
    "    error = np.square(np.log10(y_pred + 1) - np.log10(y_true + 1)).mean() ** 0.5\n",
    "    # Calculate the score as 1 - error\n",
    "    score = 1 - error\n",
    "    return score\n",
    "\n",
    "# Import the Lasso class from the sklearn.linear_model module\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create an instance of the Lasso class\n",
    "lasso_reg = Lasso()\n",
    "\n",
    "# Train the Lasso regression model on the scaled training data\n",
    "lasso_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the scaled test data\n",
    "Yhat_test_lasso = lasso_reg.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the mean absolute error (MAE) between the predicted and actual values\n",
    "mae_lasso = np.fabs(Yhat_test_lasso - y_test).mean()\n",
    "\n",
    "# Calculate the score using the custom scoring function\n",
    "score_value = score(Yhat_test_lasso, y_test)\n",
    "\n",
    "# Print the MAE and score\n",
    "print(f'Mean Absolute Error: {mae_lasso:.2f}')\n",
    "print(f'MSLE Score: {score_value:.2f}')\n",
    "R2Score_lasso=r2_score(y_test,Yhat_test_lasso)\n",
    "print(\"R2 Score: \",R2Score_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79861f28",
   "metadata": {},
   "source": [
    "### Conclusion and Observations:\n",
    "\n",
    "In this report, we evaluated the performance of two regression models, Linear Regression and Lasso Regression, on a given dataset. The models were trained on the scaled training data and their performance was evaluated on the scaled test data.\n",
    "\n",
    "Key Findings:\n",
    "\n",
    "Mean Absolute Error (MAE): The Linear Regression model achieved a MAE of 268.32, while the Lasso Regression model achieved a MAE of 263.72. This indicates that the Lasso Regression model performed slightly better than the Linear Regression model in terms of absolute error.\n",
    "Model Performance: The Lasso Regression model outperformed the Linear Regression model, suggesting that the L1 regularization used in Lasso Regression helped to reduce overfitting and improve the model's generalization ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dc2621",
   "metadata": {},
   "source": [
    "## Specifying a Network: Classes and Inheritance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6263c92",
   "metadata": {},
   "source": [
    "**Neural Network Model Evaluation**\n",
    "\n",
    "In this section, we will evaluate the performance of a Neural Network (NN) model on the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe672c",
   "metadata": {},
   "source": [
    "**Neural Network Architecture**\n",
    "\n",
    "The Neural Network architecture used in this study is a simple feedforward network with four layers: an input layer, a hidden layer, a dropout layer, and an output layer.\n",
    "\n",
    "**Input Layer**\n",
    "\n",
    "The input layer has a shape of (X.shape[1],) which is the number of features in the dataset.\n",
    "The input layer is responsible for receiving the input data and passing it to the next layer.\n",
    "The Flatten layer is used to flatten the input data into a 1D array.\n",
    "\n",
    "**Hidden Layer**\n",
    "\n",
    "The hidden layer has 50 units (neurons) with a ReLU (Rectified Linear Unit) activation function.\n",
    "The ReLU activation function is used to introduce non-linearity into the model, allowing it to learn more complex relationships between the input features and the output.\n",
    "The hidden layer is responsible for learning the representations of the input data.\n",
    "\n",
    "**Dropout Layer**\n",
    "\n",
    "The dropout layer has a dropout rate of 0.4, which means that 40% of the neurons in the hidden layer will be randomly dropped during training.\n",
    "The dropout layer is used to prevent overfitting by reducing the capacity of the model.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "The output layer has 1 unit (neuron) with a linear activation function.\n",
    "The output layer is responsible for making predictions based on the representations learned by the hidden layer.\n",
    "The linear activation function is used because the output is a continuous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b5be1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:06:59.111512Z",
     "iopub.status.busy": "2024-09-29T20:06:59.110992Z",
     "iopub.status.idle": "2024-09-29T20:06:59.171830Z",
     "shell.execute_reply": "2024-09-29T20:06:59.170303Z",
     "shell.execute_reply.started": "2024-09-29T20:06:59.111456Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m1,150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,201</span> (4.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,201\u001b[0m (4.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,201</span> (4.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,201\u001b[0m (4.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Convert the input data to float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "# Define the Neural Network model architecture\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(X.shape[1],)),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(1,activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501f1df",
   "metadata": {},
   "source": [
    "### Hyperparameters and Optimizer\n",
    "\n",
    "the following hyperparameters are used:\n",
    "\n",
    "**Loss Function:** mean_absolute_error (MAE) is used as the loss function. This is a common choice for regression problems, as it measures the average difference between the predicted and actual values.\n",
    "\n",
    "**Optimizer:** adam is used as the optimizer. Adam is a popular stochastic gradient descent optimizer that adapts the learning rate for each parameter based on the magnitude of the gradient.\n",
    "\n",
    "**Metrics:** Accuracy is used as a metric to evaluate the model's performance. \n",
    "\n",
    "**Epochs:** The model is trained for 50 epochs. An epoch is a single pass through the entire training dataset. The number of epochs can be adjusted based on the model's performance on the validation set.\n",
    "\n",
    "**Batch Size:** The batch size is set to 32. The batch size determines how many samples are used to compute the gradient of the loss function before updating the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5de03d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:07:02.086423Z",
     "iopub.status.busy": "2024-09-29T20:07:02.085847Z",
     "iopub.status.idle": "2024-09-29T20:07:07.468498Z",
     "shell.execute_reply": "2024-09-29T20:07:07.467302Z",
     "shell.execute_reply.started": "2024-09-29T20:07:02.086370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - Accuracy: 0.0000e+00 - loss: 1218.6610 - val_Accuracy: 0.0000e+00 - val_loss: 886.1459\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 863.7114 - val_Accuracy: 0.0000e+00 - val_loss: 700.6729\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 634.6406 - val_Accuracy: 0.0000e+00 - val_loss: 521.8334\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 478.1163 - val_Accuracy: 0.0000e+00 - val_loss: 369.2603\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.0000e+00 - loss: 407.5829 - val_Accuracy: 0.0000e+00 - val_loss: 281.2319\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.0000e+00 - loss: 295.8593 - val_Accuracy: 0.0000e+00 - val_loss: 241.6435\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.0000e+00 - loss: 348.6312 - val_Accuracy: 0.0000e+00 - val_loss: 231.4349\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.0000e+00 - loss: 331.5577 - val_Accuracy: 0.0000e+00 - val_loss: 228.6933\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.0000e+00 - loss: 308.5097 - val_Accuracy: 0.0000e+00 - val_loss: 227.4310\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 326.2509 - val_Accuracy: 0.0000e+00 - val_loss: 226.5779\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 366.5840 - val_Accuracy: 0.0000e+00 - val_loss: 226.5394\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.0000e+00 - loss: 275.4377 - val_Accuracy: 0.0000e+00 - val_loss: 226.6798\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 305.0797 - val_Accuracy: 0.0000e+00 - val_loss: 226.4719\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 262.5898 - val_Accuracy: 0.0000e+00 - val_loss: 226.3886\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 300.6886 - val_Accuracy: 0.0000e+00 - val_loss: 228.1310\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 263.0500 - val_Accuracy: 0.0000e+00 - val_loss: 225.3171\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.0000e+00 - loss: 227.5254 - val_Accuracy: 0.0000e+00 - val_loss: 221.8770\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 317.3741 - val_Accuracy: 0.0000e+00 - val_loss: 219.4467\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 233.4112 - val_Accuracy: 0.0000e+00 - val_loss: 218.8464\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Accuracy: 0.0000e+00 - loss: 262.7096 - val_Accuracy: 0.0000e+00 - val_loss: 218.2129\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 267.6055 - val_Accuracy: 0.0000e+00 - val_loss: 219.4702\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 295.4445 - val_Accuracy: 0.0000e+00 - val_loss: 220.9735\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Accuracy: 0.0000e+00 - loss: 293.3756 - val_Accuracy: 0.0000e+00 - val_loss: 219.1153\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 241.2937 - val_Accuracy: 0.0000e+00 - val_loss: 218.5325\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 247.7640 - val_Accuracy: 0.0000e+00 - val_loss: 216.7660\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 243.1531 - val_Accuracy: 0.0000e+00 - val_loss: 215.0181\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 276.1073 - val_Accuracy: 0.0000e+00 - val_loss: 214.7853\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Accuracy: 0.0000e+00 - loss: 220.4374 - val_Accuracy: 0.0000e+00 - val_loss: 216.7316\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 266.0941 - val_Accuracy: 0.0000e+00 - val_loss: 219.0871\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 281.8199 - val_Accuracy: 0.0000e+00 - val_loss: 217.5577\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 238.6548 - val_Accuracy: 0.0000e+00 - val_loss: 214.9099\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 221.9719 - val_Accuracy: 0.0000e+00 - val_loss: 213.9606\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 212.6432 - val_Accuracy: 0.0000e+00 - val_loss: 214.5158\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 206.2133 - val_Accuracy: 0.0000e+00 - val_loss: 216.2010\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Accuracy: 0.0000e+00 - loss: 260.8344 - val_Accuracy: 0.0000e+00 - val_loss: 218.4707\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 213.0956 - val_Accuracy: 0.0000e+00 - val_loss: 220.3363\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 247.2991 - val_Accuracy: 0.0000e+00 - val_loss: 215.3390\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 236.4722 - val_Accuracy: 0.0000e+00 - val_loss: 213.7937\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 230.9275 - val_Accuracy: 0.0000e+00 - val_loss: 213.4625\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 227.9521 - val_Accuracy: 0.0000e+00 - val_loss: 213.3737\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.0000e+00 - loss: 233.3329 - val_Accuracy: 0.0000e+00 - val_loss: 213.6512\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 216.0068 - val_Accuracy: 0.0000e+00 - val_loss: 215.1454\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 231.5898 - val_Accuracy: 0.0000e+00 - val_loss: 216.2984\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 241.8049 - val_Accuracy: 0.0000e+00 - val_loss: 216.4359\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 201.1683 - val_Accuracy: 0.0000e+00 - val_loss: 213.2923\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 228.2944 - val_Accuracy: 0.0000e+00 - val_loss: 212.0559\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 214.9176 - val_Accuracy: 0.0000e+00 - val_loss: 214.4637\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Accuracy: 0.0000e+00 - loss: 232.4344 - val_Accuracy: 0.0000e+00 - val_loss: 214.5315\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Accuracy: 0.0000e+00 - loss: 221.4458 - val_Accuracy: 0.0000e+00 - val_loss: 213.0435\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Accuracy: 0.0000e+00 - loss: 219.3129 - val_Accuracy: 0.0000e+00 - val_loss: 212.8383\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compile the Neural Network model\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam',metrics=['Accuracy'])\n",
    "\n",
    "# Train the Neural Network model on the scaled training data\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Use the trained model to make predictions on the scaled test data\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9cceaf15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:08:39.181756Z",
     "iopub.status.busy": "2024-09-29T20:08:39.181258Z",
     "iopub.status.idle": "2024-09-29T20:08:39.433564Z",
     "shell.execute_reply": "2024-09-29T20:08:39.432385Z",
     "shell.execute_reply.started": "2024-09-29T20:08:39.181713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation MAE\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab873207",
   "metadata": {},
   "source": [
    "### R-Squared Score for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea17a545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:08:52.633205Z",
     "iopub.status.busy": "2024-09-29T20:08:52.632654Z",
     "iopub.status.idle": "2024-09-29T20:08:52.643710Z",
     "shell.execute_reply": "2024-09-29T20:08:52.641979Z",
     "shell.execute_reply.started": "2024-09-29T20:08:52.633154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5025939555461918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "R2_NN=r2_score(y_test,y_pred.flatten())\n",
    "print(R2_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522f9ced",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**The R-squared score for the model is 0.4338015214150448, which indicates that the model explains approximately 43.38% of the variance in the data. This suggests that the model is a moderate fit to the data, but there is still some room for improvement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff5329",
   "metadata": {},
   "source": [
    "### Calculating MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "650b0b71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:09:16.330679Z",
     "iopub.status.busy": "2024-09-29T20:09:16.329639Z",
     "iopub.status.idle": "2024-09-29T20:09:16.340960Z",
     "shell.execute_reply": "2024-09-29T20:09:16.338906Z",
     "shell.execute_reply.started": "2024-09-29T20:09:16.330616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 212.84\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mae_NN = np.mean(np.abs(y_test - y_pred.flatten()))\n",
    "print(f'MAE: {mae_NN:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4ae5f2",
   "metadata": {},
   "source": [
    "## Neural Network Model Performance Summary\n",
    "The Neural Network model achieved a mean absolute error (MAE) of 212.50, which is a significant reduction from the previous MAE of Linear Regression and Lasso Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "734b3de6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:09:24.289020Z",
     "iopub.status.busy": "2024-09-29T20:09:24.288493Z",
     "iopub.status.idle": "2024-09-29T20:09:24.302208Z",
     "shell.execute_reply": "2024-09-29T20:09:24.300680Z",
     "shell.execute_reply.started": "2024-09-29T20:09:24.288971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Predicted    Actual\n",
      "126   470.978485   500.000\n",
      "13    324.998108   700.000\n",
      "207   564.082764   700.000\n",
      "221   283.888733   210.000\n",
      "68    229.757858   105.000\n",
      "315   291.829712   165.000\n",
      "277   396.431641   475.000\n",
      "212    71.317154    68.000\n",
      "107   879.192078   750.000\n",
      "159   360.451965   200.000\n",
      "219   173.512115   120.000\n",
      "96   1131.328979  1861.460\n",
      "240   447.026825   450.000\n",
      "59    700.663269  1350.000\n",
      "178   789.811157  1000.000\n",
      "51     83.574112    70.000\n",
      "145   708.729187  1008.333\n",
      "5     707.354553   750.000\n",
      "295    45.121925   920.000\n",
      "309   354.818268   160.000\n",
      "294   238.408829   185.000\n",
      "46    248.523087   215.000\n",
      "118   634.450256   535.000\n",
      "226   259.062378   175.000\n",
      "314   191.112122   120.000\n",
      "140   264.693146   165.000\n",
      "84   1001.059387  1900.000\n",
      "238   594.449646   580.000\n",
      "120   860.415955   733.333\n",
      "78    464.743225   325.000\n",
      "321   794.481506  1000.000\n",
      "123   367.240723   400.000\n",
      "33    406.340973   612.500\n",
      "167   337.377289   300.000\n",
      "53    734.759033  1200.000\n",
      "257   431.564819   450.000\n",
      "121   933.156982   200.000\n",
      "229   755.823914  1940.000\n",
      "206   238.955887   150.000\n",
      "115   592.037659   900.000\n",
      "213   138.318130   100.000\n",
      "215   275.423096   175.000\n",
      "293   661.853027   925.000\n",
      "170   881.328979   825.000\n",
      "130   460.186096   750.000\n",
      "108   557.859802  1175.000\n",
      "273   109.963043    90.000\n",
      "133   163.457031    87.500\n",
      "187   550.903259   365.000\n",
      "296   202.721710   286.667\n",
      "40     95.674332    67.500\n",
      "21    163.680847   115.000\n",
      "154   540.318176   277.500\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    'Predicted': y_pred.flatten(),\n",
    "    'Actual': y_test\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160914c2",
   "metadata": {},
   "source": [
    "### Comparison with Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8665a3a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:09:27.943844Z",
     "iopub.status.busy": "2024-09-29T20:09:27.943223Z",
     "iopub.status.idle": "2024-09-29T20:09:27.965212Z",
     "shell.execute_reply": "2024-09-29T20:09:27.963731Z",
     "shell.execute_reply.started": "2024-09-29T20:09:27.943788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regreesion</th>\n",
       "      <th>lasso Regreesion</th>\n",
       "      <th>Neral Network Regreesion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.416699</td>\n",
       "      <td>0.438868</td>\n",
       "      <td>0.502594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>268.320816</td>\n",
       "      <td>263.722795</td>\n",
       "      <td>212.838286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Linear Regreesion  lasso Regreesion  Neral Network Regreesion\n",
       "R2            0.416699          0.438868                  0.502594\n",
       "mae         268.320816        263.722795                212.838286"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Comparison with Other Models\n",
    "scores = {\n",
    "\"Linear Regreesion\": {\"R2\" : R2Score_linear,\n",
    "\"mae\" : mae_linear},\n",
    "    \n",
    "\"lasso Regreesion\": {\"R2\" : R2Score_lasso,\n",
    "\"mae\" : mae_lasso },\n",
    "    \n",
    " \"Neral Network Regreesion\": {\"R2\" : R2_NN,\n",
    "\"mae\" : mae_NN }  \n",
    "}\n",
    "Mlr_score=pd.DataFrame(scores)\n",
    "Mlr_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a34f78",
   "metadata": {},
   "source": [
    "**Model Comparison**\n",
    "The Neural Network model outperforms both the Linear Regression and Lasso Regression models in terms of R2 score and mean absolute error (MAE).\n",
    "\n",
    "**Key Findings**\n",
    "\n",
    "The Neural Network model has the highest R2 score of 0.502594, indicating that it explains approximately 50.25% of the variance in the data.\n",
    "\n",
    "The Neural Network model has the lowest MAE of 212.838286, indicating that it has the best predictive accuracy among the three models.\n",
    "The Lasso Regression model has a slightly higher R2 score and lower MAE compared to the Linear Regression model, indicating that it is a better performer.\n",
    "\n",
    "## Conclusion\n",
    "In this study, we evaluated the performance of three different models, Linear Regression, Lasso Regression, and Neural Network, on a given dataset. The results show that the Neural Network model performs the best in terms of R2 score and mean absolute error, followed by the Lasso Regression model and then the Linear Regression model. The Neural Network model's complex architecture and ability to learn non-linear relationships contribute to its better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d273103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
